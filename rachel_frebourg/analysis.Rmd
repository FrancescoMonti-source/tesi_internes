---
title:    "Thèse - Rachel Frébourg"
subtitle: "Comparaison avant-après niveau interdisciplinarité chez les pro de santé"
author:   "Francesco MONTI"
date:     "`r Sys.time()`" # Automatic date and time
output:
                            # Note that for engine = "mathjax", url = "local" will use a local version of 
                            # MathJax (which is copied into the output directory).
                            # For example,
                            #        See Pandoc's Manual about Math in HTML for the details about Pandoc 
                            #        supported methods.
    bookdown::html_document2: 
                                # It can be a list of
        collapse: "hide"
        toc:         yes        # Table of contents (toc): yes no
        toc_float:   yes        # yes no
        toc_depth:   5              # 1 2 3 4 5
        highlight : pygments      # default tango kate monochrome espresso pygments...
        highlight_downlit : FALSE      # TRUE to use the downlit package as syntax highlight engine to highlight 
                                       # inline code and R code chunks (including providing hyperlinks to function 
                                       # documentation). The package needs to be installed to use this feature.
        code_folding:    "hide"     # none show hide
        code_download:   yes        # yes no
        fig_caption: yes        # yes no
        fig_width : 14
        fig_height : 10
        fig_retina : 2
        theme:
            bootswatch: default        # cerulean journal flatly readable paper sandstone ...
        df_print:    default        # paged kable tibble default
        number_sections: yes        # Automatic numbering of sections: yes no
        anchor_sections : TRUE
        section_divs : TRUE     # Wrap sections in <div> tags, and attach identifiers to the enclosing <div> 
                                # rather than the header itself.
        dev : "svg"                # Graphics device to use for figure output (defaults to png)
        self_contained : TRUE
        extra_dependencies : NULL    # Extra dependencies as a list of the html_dependency class objects typically 
                                     # generated by htmltools:htmlDependency().
        css : style.css     
        includes : NULL        # Named list of additional content to include within the document 
                                # (typically created using the includes function)
        keep_md : FALSE        # Keep the markdown file generated by knitting.
        lib_dir : NULL             
        md_extensions : NULL       # Markdown extensions to be added or removed from the default definition of 
                                    # R Markdown. See the rmarkdown_format for additional details.
        pandoc_args : NULL      # Additional command line options to pass to pandoc
        template : "default"       
        math_method : "default"     
        mathjax : "default"        
editor_options: 
  chunk_output_type: console
---

```{r chunk options, echo=F}
# Chunk options
knitr::opts_chunk$set(
  echo       = T,    # Should blocks with program code be shown in knitted documents?
  eval       = TRUE,    # Should program code be evaluated?
  fig.height = 6,       # Default height for plots.
  fig.width  = 10,       # Default width for plots.
  fig.align  = "center", # Default alignment for plots in knitted documents.
  warning = F,
  tidy = T
)

```

```{r libraries and data loading, include = F}

# LIBRARIES ----------------------------------------------------------------------------------
library(conflicted)    # Get a warning/error if several functions with the same name exist.
library(magrittr)      # Operator %>% and additional pipe-friendly functions.
library(tidyverse)     # The main "tidyverse" packages.
library(openxlsx)      # Write data to Excel files.
library(stringr)
library(psych)
library(knitr)
library(kableExtra)
library(pander)
library(DT)
library(janitor)
library(plotly)
library(broom)
library(fmckage)

conflicted::conflicts_prefer(dplyr::filter)

# DATA ------------------------------------------------------------------------------------------
post = read.xlsx("Copie de resultats Q2 copie.xlsx", sheet = 1)
pre = read.xlsx("Copie de resultats Q1 copie.xlsx", sheet = 1)
```

```{r data_management, include = F}
# Colnames() to lowercase
colnames(pre) = tolower(colnames(pre))
colnames(post) = tolower(colnames(post))

# MERGING PRE E POST ----------------------------------------------------------
pre = pre %>% 
    select(-contains(c("id","submitdate","lastpage","startlanguage"))) %>% 
    rename("filiere"=b1, "id" = a1) %>% 
    mutate(test = "pre") %>% 
    mutate(across(s1q1:s7q2, as.numeric)) %>% 
    mutate(filiere = case_when(filiere == "étudiant(e) en maïeutique" ~ "maieutique",
                               filiere == "étudiant(e) en orthophonie" ~ "orthophonie",
                               filiere == "étudiant(e) en pharmacie" ~ "pharmacie",
                               filiere == "étudiant(e) IDE" ~ "IDE",
                               filiere == "étudiant(e) MKE" ~ "MKE",
                               filiere == "interne de médecine générale" ~ "medecine generale",
                               TRUE ~ NA_character_
                               )
           )

post = post %>%
    filter(!is.na(submitdate)) %>% 
    select(-contains(c("id","submitdate","lastpage","startlanguage","x26","x27"))) %>% 
    rename("id" = a1) %>% 
    left_join(pre[,c("id","filiere")], by = "id") %>% 
    relocate(filiere, .after = "id") %>% 
    mutate(test = "post") %>% 
    mutate(across(s1q1:s7q2, as.numeric))

# Merging
data = rbind(pre,post) %>% tibble

# DATA MANAGEMENT merged DF ----------------------------------------------------
data = data %>% 
    mutate(across(s1q1:s7q2, as.numeric)) %>% 
    distinct() %>% 
    relocate(test, .after = "id")

# Adding mean score column
data = data %>% mutate(score = round(rowMeans(across(s1q1:s7q2),na.rm=T),2))

# Computing missing values per row
data = data %>% filter(!is.na(id)) %>% 
    mutate(na_counts = rowSums(across(s1q1:s7q2, is.na)))
```

# Tous les questionnaires {.tabset}

## Exploration du database

```{r filtering_out_invidalid_questionnaires, include = F}
rows_1 = nrow(data)
unique_ids_1 = n_distinct(data$id)

# Removing missing IDs rows (n=4)
data = data %>% filter(!is.na(id))
unique_ids_2 = n_distinct(data$id)
rows_2 = nrow(data)

# Empty questionnaires
empty_q = sum(data$na_counts==20)


# Removing totally incomplete questionnaires
data = data %>% filter(na_counts<20)
unique_ids_3 = n_distinct(data$id)
rows_3 = nrow(data)

```

Sachant les problèmes qu'on a avec l'ID unique, pour l'analyse stat on sera obligé d'exclure tous les IDs non unique. Malheureusement la variable filière pour le "test 2" est impossible à reconstruire sans créer des doublons donc c'est le seul choix qu'on a pour l'analyse. Mais voyons quand même celui qui était notre point de départ.

A ce point là on a `r rows_1` quesitonnaires mais nous n'avons pas une idée précise de combien de sujets uniques on peut être certains d'avoir. Actuallement a `r unique_ids_1` IDs differents mais du coup on a `r rows_1-(unique_ids_1*2)` doublons.

`r empty_q` on peut les exclure parce que ils sont vides et 4 parce que l'ID est manquant, pour arriver à `r rows_3` questionnaires et `r unique_ids_3` IDs. Mettons maintenant les doublons en évidence.

```{r IDs_with_too_many_entries}
data %>% 
    group_by(id) %>% 
    summarise(n=n()) %>%
    arrange(desc(n)) %>%
    datatable(options = list(pageLength = 10,
                             #dom = 't',
                             scrollX = TRUE,
                             width = "auto",
                             scrollX = T
                             ))

problematic_IDs = data %>% group_by(id) %>% summarise(n=n()) %>% filter(n>2) %>% nrow

```

Comme tu peux le voir on semble avoir `r problematic_IDs` IDs presents **au moins** 3 fois. Creusons plus loin pour voir si on identifie un groupe d'IDs problematique. Théoriquement, si les gens avaient respecté les régles pour la création de l'identifiant anonyme, l'identifiant devrait suivre le *pattern* suivant: 1 chiffre - 2 lettres - 2 chiffres.

Voyons pour combien de lignes ce *pattern* est respecté:

```{r "looking_for_IDs_not_following_the_rules"}
str_detect(data$id, "[:digit:]{1}[:alpha:]{2}[:digit:]{2}") %>% 
    table %>%
    pander
```

Cela nous dit que **même si** on regarde seulement les gens qui ont respecté la procedure pour la création des IDs, on à tjrs des lignes de trop. D'abord, regardons les entrés des gens qui ont tapé un ID au pif (donc les "falses").

```{r "dataframe_IDs_aberrants"}
data %>% 
    filter(!str_detect(id, "[:digit:]{1}[:alpha:]{2}[:digit:]{2}")) %>%
    arrange(id) %>% 
    datatable(options = list(pageLength = 10,
                             #dom = 't',
                             scrollX = TRUE,
                             width = "auto",
                             scrollX = T
                             ))
```

Néanmoins, s'ils ont utilisé 2 fois **le même** identifiant *aberrant* on pourra quand même les apparier. Voyons donc les IDs qui apparaissent **\>2** fois. Les IDs *aberrants* qui apparaissent **2** fois on peut les utiliser, les IDs qui apparaissent qu'une seule fois, idem, on peut les garder pour la partie descriptive (carrément ils ne sera pas possible de les utiliser pour la comparaison avant-après).

```{r "IDs_aberrants_presentes_2plus_fois"}
data %>% 
    filter(!str_detect(id, "[:digit:]{1}[:alpha:]{2}[:digit:]{2}")) %>%
    group_by(id) %>%
    summarise(n=n()) %>% 
    arrange(desc(n)) %>%
    datatable(options = list(pageLength = 10,
                             #dom = 't',
                             scrollX = TRUE,
                             width = "auto",
                             scrollX = T
                             ))
```

On voit que le seul ID problematique parmi les *aberrants* est **"12345"**. Voyons les lignes qui correspondent à cet ID.

```{r filtering_on_ID_12345}
data %>% 
    filter(id=="12345") %>%
    datatable(options = list(pageLength = 10,
                             #dom = 't',
                             scrollX = TRUE,
                             width = "auto",
                             scrollX = T
                             ))
```

On semble avoir 1 IDE et 1 MG, qui ont un doublon de "2ème test". Si on regarde avec attention la ligne 3 et 4 sont identiques, avec une "filière" différente. Si la ligne 3 et 4 étaient par exemple "IDE" et la ligne 5 et 6 étaient "medecine generale" on aurait identifié des doublons --\> problème résolu. Mais dans ce cas on a des doublons **ET** 2 personnes qui ont rentré 2 fois le "2ème test" en changeant aussi de filière. Il est donc impossible de rattacher ces questionnaires à un "test 1". Ce qui est très très bizarre, est que les lignes 3 et 5 sont IDENTIQUES aux lignes 4 et 6. Ce qu'on peut faire, est prendre la moyenne des lignes 3-5 et 4-6. Le même approche nous sera utile pour gérer les IDs *non aberrants* doublons qui sont les suivants:

A ce point, avant de passer à regarder l'ensemble des tests appariés, on peut quand meme jetter un coup d'œil à "test 1" et "test 2" séparément pour voir comment les score sont distribués.

## Données manquantes

```{r all_tests_NAs}
data %>% 
  group_by(test) %>%
  count(na_counts) %>% 
  mutate("%" = round(as.numeric(n/sum(n)*100), 2)) %>% 
  ungroup() %>% 
  select(-test) %>% 
  rename("Nb missing values" = na_counts, frequency = n) %>% 
  kable(caption = "**Nb de valeurs manquantes par questionnaire**") %>% 
  kable_paper() %>% 
  pack_rows(index = c("Post"=6,"Pre"=7))
```

## Distribution "filière" filière (1er fichier)

```{r 1st_test_distribution_filiere}
g = pre %>% 
    ggplot(aes(x=filiere))+
    geom_bar()+
    labs(title = "Distribution par filière au moment du 1er test")+
    scale_y_continuous(breaks = seq(0, 1000, 10))

ggplotly()
```

## Distribution score moyen du questionnaire

```{r all_tests_dispersion_measures}
    # describe tables
rbind(describe(data$score, fast = T),
      describe(data$score[data$test=="pre"], fast = T),
      describe(data$score[data$test=="post"], fast = T)) %>% 
    as.data.frame(row.names = c("Ensemble", "pre", "post")) %>%
    rename(deviation_standard = sd, ecart_type = se) %>% 
    kable(caption = "**Score - Tous tests confondus - Mesures de dispersion**",digits = 3) %>%
    kable_styling(full_width = T) %>% 
  kable_paper()

    # idem by filière
pre %>%
    mutate(score = round(rowMeans(across(s1q1:s7q2),na.rm=T),2)) %>% 
    group_by(filiere) %>% summarise(describe(score,fast=T)) %>% 
    as.data.frame(row.names = c("Ensemble", "pre", "post")) %>%
    rename(deviation_standard = sd, ecart_type = se) %>% 
    kable(caption = "**score - 1er test - Mesures de dispersion by filière**",digits = 3)%>%
    kable_styling(full_width = T) %>% 
  kable_paper()
```

```{r 1st_test_score_histogramme}
g = data %>% 
 # pivot_longer(cols = c("post", "pre"), names_to = "test", values_to = "score") %>%
  mutate(score = round(score, 2)) %>%
  mutate(score = factor(score, levels = rev(sort(unique(score))))) %>%
  mutate(score = cut(as.numeric(as.character(score)), breaks = 12)) %>%
  ggplot(aes(x = score)) +
  geom_bar(aes(fill = test), alpha = 0.3, position = "identity") +
  scale_y_continuous(breaks = seq(0, 1000, 10)) +
  labs(title = "Distribution score moyen")+
  theme(title = element_text(face = "bold"))

ggplotly()

```

# ID uniques {.tabset}

Prenons maintenant la population composée seulement par des IDs uniques (qui apparaissent au max 1 fois par test).

```{r preparing_data_id_uniques}
post = read.xlsx("Copie de resultats Q2 copie.xlsx", sheet = 1)
pre = read.xlsx("Copie de resultats Q1 copie.xlsx", sheet = 1)

colnames(pre) = tolower(colnames(pre))
colnames(post) = tolower(colnames(post))

# cleaning and preparing "pre" ----------------------------------
pre = pre %>% 
    select(-contains(c("id","submitdate","lastpage","startlanguage"))) %>% 
    rename("filiere"=b1, "id" = a1) %>% 
    mutate(test = "pre") %>% 
    mutate(across(s1q1:s7q2, as.numeric)) %>% 
    mutate(filiere = case_when(filiere == "étudiant(e) en maïeutique" ~ "maieutique",
                               filiere == "étudiant(e) en orthophonie" ~ "orthophonie",
                               filiere == "étudiant(e) en pharmacie" ~ "pharmacie",
                               filiere == "étudiant(e) IDE" ~ "IDE",
                               filiere == "étudiant(e) MKE" ~ "MKE",
                               filiere == "interne de médecine générale" ~ "medecine generale",
                               TRUE ~ NA_character_
                               )
           )

# cleaning and preparing "post" ----------------------------------
post = post %>%
    filter(!is.na(submitdate)) %>% 
    select(-contains(c("id","submitdate","lastpage","startlanguage","x26","x27"))) %>% 
    rename("id" = a1) %>% 
    left_join(pre[,c("id","filiere")], by = "id") %>% 
    relocate(filiere, .after = "id") %>% 
    mutate(test = "post") %>% 
    mutate(across(s1q1:s7q2, as.numeric))

# excluding IDs appearing more than 1 time ---------------------------
pre_index = pre %>% group_by(id) %>% count %>% filter(n==1) %>% pull(id)
post_index = post %>% group_by(id) %>% count %>% filter(n==1) %>% pull(id)

pre = pre %>% filter(id %in% pre_index)
post = post %>% filter(id %in% post_index)

# merge --------------------------------------------------------------------
data = rbind(pre, post) %>% 
    mutate(na_counts = rowSums(across(s1q1:s7q2, is.na))) %>% 
    filter(na_counts<20) %>% 
    mutate(score = round(rowMeans(across(s1q1:s7q2),na.rm=T),2))
```

## Taille population et distribution par filière

Nous avons un total de `r n_distinct(data$id)` sujets, repartis de la façon suivante. Attention, ceux ne sont pas encore les sujets qui ont fait les 2 tests, ceux ci sont tous les IDs qui apparaissent au max 1 fois par test.

```{r sujets_distribution_par_filiere}
data %>% 
  distinct(id,filiere) %$% 
    table(filiere,useNA = "ifany") %>% 
    as.data.frame() %>% 
    mutate("%" = round(Freq/sum(Freq)*100, 3)) %>% 
    rename("Nb sujet participants" = Freq) %>% 
    adorn_totals() %>% 
    kable(caption = "**Repartition sujets par filière**", digit=2) %>% 
  kable_paper()

```

Voyons qui sont les 8 sujets sans filière:

```{r}
x = data %>% filter(is.na(filiere))  %>% pull(id)

data %>% 
    filter(id %in% x) %>% 
    relocate(test, .after=id) %>% 
    datatable(options = list(
      pageLength = 10,
      scrollX = TRUE,
      width = "auto",
      scrollX = TRUE
  ))
```

Apparémment ce sont des gens qui ont fait seulement le 2ème test.

## Données manquantes
Voyons sur tout l'ensemble de tests, combien de données manquantes on a. Ce sont des "vraies" données manquantes **OU** des "NSP" qui n'était pas pertinents pour la question et vraisemblablement pris pour des *"Ne sait pas".*

```{r exploring_missing_values_frequencies}
table(data$na_counts) %>% 
    as.data.frame() %>% 
    mutate("%" = round(as.numeric(Freq/sum(Freq)*100), 2),
           Var1 = round(as.numeric(as.character(Var1)),2)) %>% 
    rename("Nb missing values" = Var1) %>% 
    kable(caption = "**Nb de valeurs manquantes par questionnaire**") %>% 
  kable_paper()

```

On voit que les tests sont bien complets globalement. Seulement 7 questionnaires ont **\>=3** valeurs manquantes.

## Distribution "filière"

```{r}
g = data %>% 
    ggplot(aes(x=filiere))+
    geom_bar()+
    labs(title = "Distribution par filière IDs uniques")+
    scale_y_continuous(breaks = seq(0, 1000, 10))+
  scale_x_discrete(na.translate=T)+
  theme(title = element_text(face = "bold"))

ggplotly()
```

La différence par rapport à la distribution précédente est presque invisible, ce qui est bien. Nous ne sommes pas en train d'introduire des biais comme involontairement sélectionner une sous-population spécifique.

## Distribution score moyen
```{r}
rbind(describe(data$score, fast = T),
      describe(data$score[data$test=="pre"], fast = T),
      describe(data$score[data$test=="post"], fast = T)) %>% 
    as.data.frame(row.names = c("Ensemble", "pre", "post")) %>%
    rename(deviation_standard = sd, ecart_type = se) %>% 
    kable(caption = "<b>Score - ID uniques - Mesures de dispersion<b>", 
          digits = 3) %>%
    kable_styling(full_width = T, ) %>% 
    kable_paper()

    # idem by filière
pre %>%
    mutate(score = round(rowMeans(across(s1q1:s7q2),na.rm=T),2)) %>% 
    group_by(filiere) %>% 
    summarise(describe(score,fast=T)) %>% 
    as.data.frame(row.names = c("Ensemble", "pre", "post")) %>%
    rename(deviation_standard = sd, ecart_type = se) %>% 
    kable(caption = "<b>Score - ID uniques - Mesures de dispersion by filière<b>",
          digits = 3) %>%
    kable_styling(full_width = T) %>% 
    kable_paper()
```

```{r id_uniques_score_distribution}
g = data %>% 
 # pivot_longer(cols = c("post", "pre"), names_to = "test", values_to = "score") %>%
  mutate(score = round(score, 2)) %>%
  mutate(score = factor(score, levels = rev(sort(unique(score))))) %>%
  mutate(score = cut(as.numeric(as.character(score)), breaks = 12)) %>%
  ggplot(aes(x = score)) +
  geom_bar(aes(fill = test), alpha = 0.3, position = "identity") +
  scale_y_continuous(breaks = seq(0, 1000, 10))+
    scale_x_discrete(na.translate = F)+
  #coord_flip() +
  labs(title = "Distribution score moyen") +
  theme(title = element_text(face = "bold"))

ggplotly()

```


# IDs appariés {.tabset}

```{r summarise_by_filiere}


# Creating table paired_questionnaires
tab_paired_questionnaires <- data %>%
  group_by(id, filiere) %>%
  summarise(n = n(), .groups = "drop") %>%
  arrange(desc(n)) %$%
  table(filiere, n) %>%
  data.frame() %>%
  pivot_wider(names_from = n, values_from = Freq) %>%
  setNames(c("Filiere", "Tests non apparies", "Tests apparies"))


data %>%
  group_by(filiere) %>%
  summarise(id = n_distinct(id),nb_questionnaires = n(), 
            valeurs_manquantes = as.integer(sum(na_counts,na.rm=T))
  ) %>%
  left_join(tab_paired_questionnaires, by = c("filiere" = "Filiere")) %>% 
  mutate(across(c(id:`Tests apparies`),
                ~paste0(.x, " (", round(.*100/sum(.,na.rm=T),2), "%)", 
                        sep = ""))
      ) %>% 
  select(-ends_with("%")) %>% 
  datatable(options = list(
    pageLength = 10,
    scrollX = TRUE,
    width = "auto",
    scrollX = TRUE
  ))

```

On voit qu'il y a quelque chose de bizarre avec la dernière ligne du tableau. Voyons.

```{r}

```

## Distribution score moyen par question

```{r}
data %>% 
  pivot_longer(cols = s1q1:s7q2, names_to = "question", values_to = "value") %>% 
  group_by(question) %>% 
  summarise(describe(fast=T, value)) %>% ungroup() %>% 
  mutate(across(where(is.numeric),round,3)) %>% 
  datatable(options = list(
    pageLength = 10,
    scrollX = TRUE,
    width = "auto",
    scrollX = TRUE,
    caption = "Score - Mésures de distribution par question"
  ))
  
```

# Statistiques

## Descriptives {.tabset}

```{r t-test_tous_confondus}
# DF with id-filiere-pre-post pour les tests stat
paired_data <- data %>%
  group_by(id, filiere, test) %>%
  summarise(mean_score = mean(c_across(s1q1:s7q2), na.rm = T), .groups = "drop") %>%
  pivot_wider(names_from = "test", values_from = "mean_score") %>%
    filter(!is.na(post),!is.na(pre)) %>% distinct

```

### Mesures de dispersion - tests appariés

```{r dispersion_measures_paired_tests}
# paired tests -------------------------------------
    # describe tables
paired_data %>%
  pivot_longer(
    cols = c("pre", "post"),
    names_to = "time",
    values_to = "value"
  ) %>%
  summarise(
    filiere = "Overall",
    time = "Overall",
    mean = mean(value, na.rm = TRUE),
    median = median(value, na.rm = TRUE),
    deviation_standard = sd(value, na.rm = TRUE),
    ecart_type = sd(value, na.rm = TRUE) / sqrt(sum(!is.na(value)))
    ) %>% 
    mutate(across(is.numeric,round,2)) %>% 
    kable(caption = "Tests appariés - mesures de dispersion") %>%
    kable_styling(full_width = T)

    # idem by filière
paired_data %>%
    pivot_longer(cols = c("pre", "post"),
                 names_to = "time",
                 values_to = "value") %>% group_by(filiere, time) %>%
    summarise(mean = mean(value, na.rm = TRUE),
              median = median(value, na.rm = TRUE),
              deviation_standard = sd(value, na.rm = TRUE),
              ecart_type = sd(value, na.rm = TRUE) / sqrt(sum(!is.na(value)))) %>%
    mutate(across(is.numeric,round,2)) %>% 
    kable(caption = "Tests appariés - mesures de dispersion by filière") %>%
    kable_styling(full_width = T)


```

### Test de Wilcoxon sur données appariées

Pour realiser un test de student, une parmi les plusieurs conditions de validité est que la variable qu'on étudie doit suivre la *loi normale*: sa distribution a une forme en cloche simmetrique. Or, on voit que dans notre cas, ce n'est pas du tout le cas. Cela nous rend "impossible" ("" parce que en vrai je peux quand meme le lancer sans soucis le test et très probablement personne te demanderait si tu as verifié les conditions de validité du test) utiliser le *t student* et on va devoir "se contenter" d'un test *non-parametrique* (quand la variable étudie ne suit pas une distribution précise, comme la loi normale par example).

```{r distribution_scores_by_filiere, fig.height=10}
paired_data %>%
  pivot_longer(cols = c("post", "pre"), names_to = "test", values_to = "score") %>%
  mutate(score = round(score, 2)) %>%
  mutate(score = factor(score, levels = rev(sort(unique(score))))) %>%
  mutate(score = cut(as.numeric(as.character(score)), breaks = 20)) %>%
  ggplot(aes(x = score)) +
  geom_bar(aes(fill = test), alpha = 0.3, position = "identity") +
  scale_y_continuous(breaks = seq(0, 1000, 10)) +
  coord_flip() +
  labs(title = "Mean questionnaire score distribution") +
  facet_wrap(vars(filiere), ncol = 2)
```

L'equivalent non parametrique du *t student apparié* est le test de rang signé de wilcoxon avec correction de continuité. Je me repète, le test du rang signé de Wilcoxon est un test statistique non paramétrique qui compare deux échantillons apparentés ou des mesures répétées sur un seul échantillon afin d'évaluer si les rangs moyens de leur population diffèrent (c'est-à-dire qu'il s'agit d'un test de différence par paires). Il peut être utilisé comme alternative au test t de Student lorsque la population ne peut pas être supposée normalement distribuée.

En statistique, le "rang" fait référence à la position d'une valeur particulière au sein d'un ensemble de données lorsqu'elles sont classées par ordre croissant ou décroissant.

Par exemple, considérons l'ensemble de données suivant : {3, 7, 1, 4, 6}. Si nous le classons par ordre croissant, nous obtenons {1, 3, 4, 6, 7}. Le "rang" de chaque nombre dans l'ensemble de données original est alors sa position dans l'ensemble de données ordonné. Ainsi, le rang de 3 est 2, le rang de 7 est 5, le rang de 1 est 1, le rang de 4 est 3 et le rang de 6 est 4.

Dans le cadre du test du rang signé de Wilcoxon, les différences entre des observations appariées sont classées en fonction de leur valeur absolue. Le signe de la différence est ensuite appliqué au rang. Cela permet au test de prendre en compte à la fois l'ampleur des différences (par le biais des rangs des différences absolues) et le sens des différences (par le biais des signes).

Pense à l'ECN: on veut comparer la performance des éléves de 2 lycées. Le test de wilcoxon pourrait nous aider à répondre à la question "est-ce que si le classement (rang) median des élèves d'un lycée X ou Y est meilleure que le classement (rang) median de l'autre.

Je vais lancer le test sur l'ensemble de la population et t'expliquer le résultat.

```{r}
wilcox.test(paired_data$post,
                        paired_data$pre, paired = T
                       )
```

-   **"Test de rang signé de Wilcoxon avec correction de continuité"** : Ceci indique le test spécifique utilisé. La partie "correction de continuité" est une technique permettant d'ajuster le test de rang signé de Wilcoxon pour tenir compte du fait que nous utilisons une version discrète d'une distribution continue.

-   **"Données : paired_data\$post et paired_data\$pre"** : Ceci spécifie les deux ensembles de mesures ou d'observations qui ont été comparés dans le test.

-   **"V = 52171"**: Il s'agit de la statistique du test. Pour le test du rang signé de Wilcoxon, il s'agit de la somme des rangs des différences positives (ou de la somme des rangs négatifs, selon le logiciel utilisé).

-   **"p-value \< 2.2e-16"** : Il s'agit de la valeur p du test, qui est utilisée pour interpréter les résultats. Si la valeur p est inférieure au seuil de signification choisi (souvent 0,05), l'hypothèse nulle est rejetée. Dans ce cas, la valeur p est extrêmement faible, et il y a donc de bonnes raisons de rejeter l'hypothèse nulle.

-   **"Hypothèse alternative : le véritable distance entre les 2 medianes n'est pas égal à 0"** : Il s'agit de l'hypothèse alternative du test. Pour le test du rang signé de Wilcoxon, l'hypothèse nulle est que la médiane des différences entre les paires d'observations est égale à zéro. Cette hypothèse alternative indique que la véritable médiane des différences n'est pas nulle.

En termes simples, le test indique qu'il existe une différence statistiquement significative entre les mesures avant et après dans ces données appariées, avec une valeur p très faible (\<0.001) fournissant une preuve solide contre l'hypothèse nulle.

Je vais faire la même chose pour chaque filière prise singulièrement.

```{r t.test_by_filiere, fig.height=10, eval=F}
# initialising emtpty list
results <- list()

#Iteration over filiere
 # for (index in unique(data$filiere)) {
 #   test <- t.test(paired_data$post[paired_data$filiere == index],
 #     paired_data$pre[paired_data$filiere == index],
 #     paired = TRUE, var.equal = F
 #   )
 # 
 #   results[[index]] <- test
 # }

 for (index in unique(data$filiere)) {
   test <- wilcox.test(paired_data$post[paired_data$filiere == index],
     paired_data$pre[paired_data$filiere == index],
     paired = T
   )

   results[[index]] <- test
 }


 # Formatting results
 result_df <- lapply(results, function(test) {
   data.frame(
       # mean_score_difference = test$estimate,
       p.value = pval_format(test$p.value),
       #conf = test$conf.int,
       #low_high_tag = rep(c("conf.low","conf.high")),
       method = test$method
       )
     }
   )

 # Merge the data frames in the list
 merged_df <- bind_rows(result_df, .id = "filiere")

 merged_df %>% pander()
 
 # Print the merged data frame
 # merged_df %>%
 #   pivot_wider(values_from = conf, names_from = low_high_tag) %>%
 #   mutate(across(where(is.numeric), round, 3)) %>%
 #   left_join(tab_paired_questionnaires[c("Filiere", "Tests apparies")],
 #             by = c("filiere" = "Filiere")
 #   ) %>%
 #     arrange(filiere) %>%
 #     rename(n = "Tests apparies") %>%
 #     relocate(n, .after = "filiere") %>%
 #     relocate(method, .after = last_col()) %>%
 #     relocate(p.value, .after = last_col()) %>%
 #     mutate(n = paste(n, "/",
 #                    tab_paired_questionnaires$`Tests non apparies` +
 #                                         tab_paired_questionnaires$`Tests apparies`,
 #                    sep = "")) %>%
 # 
 #     datatable(options = list(pageLength = 10,
 #                              #dom = 't',
 #                              scrollX = TRUE,
 #                              width = "auto",
 #                              scrollX = T
 #                              ))

```
